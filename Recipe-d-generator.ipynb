{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pressed-kelly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.4.1\n",
      "Keras version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import pathlib\n",
    "import os\n",
    "import json\n",
    "\n",
    "print('Tensorflow version:', tf.__version__)\n",
    "print('Keras version:', tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seeing-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('recipe1M_layers/layer1.json', 'r') as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chubby-transparency",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ingredients': [{'text': '6 ounces penne'},\n",
       "  {'text': '2 cups Beechers Flagship Cheese Sauce (recipe follows)'},\n",
       "  {'text': '1 ounce Cheddar, grated (1/4 cup)'},\n",
       "  {'text': '1 ounce Gruyere cheese, grated (1/4 cup)'},\n",
       "  {'text': '1/4 to 1/2 teaspoon chipotle chili powder (see Note)'},\n",
       "  {'text': '1/4 cup (1/2 stick) unsalted butter'},\n",
       "  {'text': '1/3 cup all-purpose flour'},\n",
       "  {'text': '3 cups milk'},\n",
       "  {'text': '14 ounces semihard cheese (page 23), grated (about 3 1/2 cups)'},\n",
       "  {'text': '2 ounces semisoft cheese (page 23), grated (1/2 cup)'},\n",
       "  {'text': '1/2 teaspoon kosher salt'},\n",
       "  {'text': '1/4 to 1/2 teaspoon chipotle chili powder'},\n",
       "  {'text': '1/8 teaspoon garlic powder'},\n",
       "  {'text': '(makes about 4 cups)'}],\n",
       " 'url': 'http://www.epicurious.com/recipes/food/views/-world-s-best-mac-and-cheese-387747',\n",
       " 'partition': 'train',\n",
       " 'title': 'Worlds Best Mac and Cheese',\n",
       " 'id': '000018c8a5',\n",
       " 'instructions': [{'text': 'Preheat the oven to 350 F. Butter or oil an 8-inch baking dish.'},\n",
       "  {'text': 'Cook the penne 2 minutes less than package directions.'},\n",
       "  {'text': '(It will finish cooking in the oven.)'},\n",
       "  {'text': 'Rinse the pasta in cold water and set aside.'},\n",
       "  {'text': 'Combine the cooked pasta and the sauce in a medium bowl and mix carefully but thoroughly.'},\n",
       "  {'text': 'Scrape the pasta into the prepared baking dish.'},\n",
       "  {'text': 'Sprinkle the top with the cheeses and then the chili powder.'},\n",
       "  {'text': 'Bake, uncovered, for 20 minutes.'},\n",
       "  {'text': 'Let the mac and cheese sit for 5 minutes before serving.'},\n",
       "  {'text': 'Melt the butter in a heavy-bottomed saucepan over medium heat and whisk in the flour.'},\n",
       "  {'text': 'Continue whisking and cooking for 2 minutes.'},\n",
       "  {'text': 'Slowly add the milk, whisking constantly.'},\n",
       "  {'text': 'Cook until the sauce thickens, about 10 minutes, stirring frequently.'},\n",
       "  {'text': 'Remove from the heat.'},\n",
       "  {'text': 'Add the cheeses, salt, chili powder, and garlic powder.'},\n",
       "  {'text': 'Stir until the cheese is melted and all ingredients are incorporated, about 3 minutes.'},\n",
       "  {'text': 'Use immediately, or refrigerate for up to 3 days.'},\n",
       "  {'text': 'This sauce reheats nicely on the stove in a saucepan over low heat.'},\n",
       "  {'text': 'Stir frequently so the sauce doesnt scorch.'},\n",
       "  {'text': 'This recipe can be assembled before baking and frozen for up to 3 monthsjust be sure to use a freezer-to-oven pan and increase the baking time to 50 minutes.'},\n",
       "  {'text': 'One-half teaspoon of chipotle chili powder makes a spicy mac, so make sure your family and friends can handle it!'},\n",
       "  {'text': 'The proportion of pasta to cheese sauce is crucial to the success of the dish.'},\n",
       "  {'text': 'It will look like a lot of sauce for the pasta, but some of the liquid will be absorbed.'}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "advance-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_raw = []\n",
    "for record in dataset:\n",
    "    record_clean = {\n",
    "        \"title\": record[\"title\"],\n",
    "        \"ingredients\": [ingredient[\"text\"] for ingredient in record[\"ingredients\"]],\n",
    "        \"instructions\": \"\\n\".join([instruction[\"text\"] for instruction in record[\"instructions\"]]),\n",
    "        \"id\": record[\"id\"],\n",
    "        \"partition\": record[\"partition\"]\n",
    "    }\n",
    "    dataset_raw.append(record_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "seeing-melissa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1029720"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "encouraging-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters out recipes which don't have either title or ingredients or instructions or partition or id.\n",
    "def recipe_validate_required_fields(recipe):\n",
    "    required_keys = ['title', 'ingredients', 'instructions', 'partition', 'id']\n",
    "    \n",
    "    if not recipe:\n",
    "        return False\n",
    "    \n",
    "    for required_key in required_keys:\n",
    "        if not recipe[required_key]:\n",
    "            return False\n",
    "        \n",
    "        if type(recipe[required_key]) == list and len(recipe[required_key]) == 0:\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "assumed-sapphire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size BEFORE validation 1029720\n",
      "Dataset size AFTER validation 1029720\n",
      "Number of invalid recipes 0\n"
     ]
    }
   ],
   "source": [
    "dataset_validated = [recipe for recipe in dataset_raw if recipe_validate_required_fields(recipe)]\n",
    "\n",
    "print('Dataset size BEFORE validation', len(dataset_raw))\n",
    "print('Dataset size AFTER validation', len(dataset_validated))\n",
    "print('Number of invalid recipes', len(dataset_raw) - len(dataset_validated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nutritional-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORD_TITLE = 'üìó '\n",
    "STOP_WORD_INGREDIENTS = '\\nü•ï\\n\\n'\n",
    "STOP_WORD_INSTRUCTIONS = '\\nüìù\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "collectible-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts recipe object to string (sequence of characters) for later usage in RNN input.\n",
    "def recipe_to_string(recipe):\n",
    "    \n",
    "    title = recipe['title']\n",
    "    ingredients = recipe['ingredients']\n",
    "    instructions = recipe['instructions'].split('\\n')\n",
    "    \n",
    "    ingredients_string = ''\n",
    "    for ingredient in ingredients:\n",
    "        if ingredient:\n",
    "            ingredients_string += f'‚Ä¢ {ingredient}\\n'\n",
    "    \n",
    "    instructions_string = ''\n",
    "    for instruction in instructions:\n",
    "        if instruction:\n",
    "            instructions_string += f'‚ñ™Ô∏é {instruction}\\n'\n",
    "    \n",
    "    return f'{STOP_WORD_TITLE}{title}\\n{STOP_WORD_INGREDIENTS}{ingredients_string}{STOP_WORD_INSTRUCTIONS}{instructions_string}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "irish-study",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stringified dataset size:  1029720\n"
     ]
    }
   ],
   "source": [
    "dataset_stringified = [recipe_to_string(recipe) for recipe in dataset_validated]\n",
    "\n",
    "print('Stringified dataset size: ', len(dataset_stringified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "premium-estimate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe #1\n",
      "---------\n",
      "üìó Worlds Best Mac and Cheese\n",
      "\n",
      "ü•ï\n",
      "\n",
      "‚Ä¢ 6 ounces penne\n",
      "‚Ä¢ 2 cups Beechers Flagship Cheese Sauce (recipe follows)\n",
      "‚Ä¢ 1 ounce Cheddar, grated (1/4 cup)\n",
      "‚Ä¢ 1 ounce Gruyere cheese, grated (1/4 cup)\n",
      "‚Ä¢ 1/4 to 1/2 teaspoon chipotle chili powder (see Note)\n",
      "‚Ä¢ 1/4 cup (1/2 stick) unsalted butter\n",
      "‚Ä¢ 1/3 cup all-purpose flour\n",
      "‚Ä¢ 3 cups milk\n",
      "‚Ä¢ 14 ounces semihard cheese (page 23), grated (about 3 1/2 cups)\n",
      "‚Ä¢ 2 ounces semisoft cheese (page 23), grated (1/2 cup)\n",
      "‚Ä¢ 1/2 teaspoon kosher salt\n",
      "‚Ä¢ 1/4 to 1/2 teaspoon chipotle chili powder\n",
      "‚Ä¢ 1/8 teaspoon garlic powder\n",
      "‚Ä¢ (makes about 4 cups)\n",
      "\n",
      "üìù\n",
      "\n",
      "‚ñ™Ô∏é Preheat the oven to 350 F. Butter or oil an 8-inch baking dish.\n",
      "‚ñ™Ô∏é Cook the penne 2 minutes less than package directions.\n",
      "‚ñ™Ô∏é (It will finish cooking in the oven.)\n",
      "‚ñ™Ô∏é Rinse the pasta in cold water and set aside.\n",
      "‚ñ™Ô∏é Combine the cooked pasta and the sauce in a medium bowl and mix carefully but thoroughly.\n",
      "‚ñ™Ô∏é Scrape the pasta into the prepared baking dish.\n",
      "‚ñ™Ô∏é Sprinkle the top with the cheeses and then the chili powder.\n",
      "‚ñ™Ô∏é Bake, uncovered, for 20 minutes.\n",
      "‚ñ™Ô∏é Let the mac and cheese sit for 5 minutes before serving.\n",
      "‚ñ™Ô∏é Melt the butter in a heavy-bottomed saucepan over medium heat and whisk in the flour.\n",
      "‚ñ™Ô∏é Continue whisking and cooking for 2 minutes.\n",
      "‚ñ™Ô∏é Slowly add the milk, whisking constantly.\n",
      "‚ñ™Ô∏é Cook until the sauce thickens, about 10 minutes, stirring frequently.\n",
      "‚ñ™Ô∏é Remove from the heat.\n",
      "‚ñ™Ô∏é Add the cheeses, salt, chili powder, and garlic powder.\n",
      "‚ñ™Ô∏é Stir until the cheese is melted and all ingredients are incorporated, about 3 minutes.\n",
      "‚ñ™Ô∏é Use immediately, or refrigerate for up to 3 days.\n",
      "‚ñ™Ô∏é This sauce reheats nicely on the stove in a saucepan over low heat.\n",
      "‚ñ™Ô∏é Stir frequently so the sauce doesnt scorch.\n",
      "‚ñ™Ô∏é This recipe can be assembled before baking and frozen for up to 3 monthsjust be sure to use a freezer-to-oven pan and increase the baking time to 50 minutes.\n",
      "‚ñ™Ô∏é One-half teaspoon of chipotle chili powder makes a spicy mac, so make sure your family and friends can handle it!\n",
      "‚ñ™Ô∏é The proportion of pasta to cheese sauce is crucial to the success of the dish.\n",
      "‚ñ™Ô∏é It will look like a lot of sauce for the pasta, but some of the liquid will be absorbed.\n",
      "\n",
      "\n",
      "\n",
      "Recipe #2\n",
      "---------\n",
      "üìó Dilly Macaroni Salad Recipe\n",
      "\n",
      "ü•ï\n",
      "\n",
      "‚Ä¢ 1 c. elbow macaroni\n",
      "‚Ä¢ 1 c. cubed American cheese (4 ounce.)\n",
      "‚Ä¢ 1/2 c. sliced celery\n",
      "‚Ä¢ 1/2 c. minced green pepper\n",
      "‚Ä¢ 3 tbsp. minced pimento\n",
      "‚Ä¢ 1/2 c. mayonnaise or possibly salad dressing\n",
      "‚Ä¢ 1 tbsp. vinegar\n",
      "‚Ä¢ 3/4 teaspoon salt\n",
      "‚Ä¢ 1/2 teaspoon dry dill weed\n",
      "\n",
      "üìù\n",
      "\n",
      "‚ñ™Ô∏é Cook macaroni according to package directions; drain well.\n",
      "‚ñ™Ô∏é Cold.\n",
      "‚ñ™Ô∏é Combine macaroni, cheese cubes, celery, green pepper and pimento.\n",
      "‚ñ™Ô∏é Blend together mayonnaise or possibly salad dressing, vinegar, salt and dill weed; add in to macaroni mix.\n",
      "‚ñ™Ô∏é Toss lightly.\n",
      "‚ñ™Ô∏é Cover and refrigeratewell.\n",
      "‚ñ™Ô∏é Serve salad in lettuce lined bowl if you like.\n",
      "‚ñ™Ô∏é Makes 6 servings.\n",
      "\n",
      "\n",
      "\n",
      "Recipe #3\n",
      "---------\n",
      "üìó Gazpacho\n",
      "\n",
      "ü•ï\n",
      "\n",
      "‚Ä¢ 8 tomatoes, quartered\n",
      "‚Ä¢ Kosher salt\n",
      "‚Ä¢ 1 red onion, cut into small dice\n",
      "‚Ä¢ 1 green bell pepper, cut into small dice\n",
      "‚Ä¢ 1 red bell pepper, cut into small dice\n",
      "‚Ä¢ 1 yellow bell pepper, cut into small dice\n",
      "‚Ä¢ 1/2 cucumber, cut into small dice\n",
      "‚Ä¢ Extra-virgin olive oil, for drizzling\n",
      "‚Ä¢ 3 leaves fresh basil, finely chopped\n",
      "\n",
      "üìù\n",
      "\n",
      "‚ñ™Ô∏é Add the tomatoes to a food processor with a pinch of salt and puree until smooth.\n",
      "‚ñ™Ô∏é Combine the onions, bell peppers and cucumbers with the tomato puree in a large bowl.\n",
      "‚ñ™Ô∏é Chill at least 1 hour.\n",
      "‚ñ™Ô∏é Drizzle with olive oil, garnish with chopped basil and serve.\n",
      "\n",
      "\n",
      "\n",
      "Recipe #4\n",
      "---------\n",
      "üìó Crunchy Onion Potato Bake\n",
      "\n",
      "ü•ï\n",
      "\n",
      "‚Ä¢ 2 12 cups milk\n",
      "‚Ä¢ 1 12 cups water\n",
      "‚Ä¢ 14 cup butter\n",
      "‚Ä¢ mashed potatoes, 1 box, homestyle\n",
      "‚Ä¢ 1 (8 ounce) can whole kernel corn (drained)\n",
      "‚Ä¢ 1 cup cheddar cheese\n",
      "‚Ä¢ 1 cup French-fried onions\n",
      "\n",
      "üìù\n",
      "\n",
      "‚ñ™Ô∏é Preheat oven to 350 degrees Fahrenheit.\n",
      "‚ñ™Ô∏é Spray pan with non stick cooking spray.\n",
      "‚ñ™Ô∏é Heat milk, water and butter to boiling; stir in contents of both pouches of potatoes; let stand one minute.\n",
      "‚ñ™Ô∏é Stir in corn.\n",
      "‚ñ™Ô∏é Spoon half the potato mixture in pan.\n",
      "‚ñ™Ô∏é Sprinkle half each of cheese and onions; top with remaining potatoes.\n",
      "‚ñ™Ô∏é Sprinkle with remaining cheese and onions.\n",
      "‚ñ™Ô∏é Bake 10 to 15 minutes until cheese is melted.\n",
      "‚ñ™Ô∏é Enjoy !\n",
      "\n",
      "\n",
      "\n",
      "Recipe #5\n",
      "---------\n",
      "üìó Cool 'n Easy Creamy Watermelon Pie\n",
      "\n",
      "ü•ï\n",
      "\n",
      "‚Ä¢ 1 (3 ounce) package watermelon gelatin\n",
      "‚Ä¢ 14 cup boiling water\n",
      "‚Ä¢ 1 (12 ounce) package Cool Whip, thawed\n",
      "‚Ä¢ 2 cups cubed seedless watermelon\n",
      "‚Ä¢ 1 graham cracker crust\n",
      "\n",
      "üìù\n",
      "\n",
      "‚ñ™Ô∏é Dissolve Jello in boiling water.\n",
      "‚ñ™Ô∏é Allow to cool to room temp.\n",
      "‚ñ™Ô∏é Whisk in Cool Whip.\n",
      "‚ñ™Ô∏é Fold in watermelon.\n",
      "‚ñ™Ô∏é Spoon into crust.\n",
      "‚ñ™Ô∏é Chill for 2-3 hours or overnight.\n",
      "‚ñ™Ô∏é Yum!\n",
      "\n",
      "\n",
      "\n",
      "Recipe #6\n",
      "---------\n",
      "üìó Easy Tropical Beef Skillet\n",
      "\n",
      "ü•ï\n",
      "\n",
      "‚Ä¢ 12 cup shredded coconut\n",
      "‚Ä¢ 1 lb lean ground beef\n",
      "‚Ä¢ 1 -2 tablespoon minced fresh garlic (or to taste)\n",
      "‚Ä¢ salt and black pepper\n",
      "‚Ä¢ 1 tablespoon lemon juice\n",
      "‚Ä¢ 1 tablespoon soy sauce\n",
      "‚Ä¢ 2 tablespoons cornstarch\n",
      "‚Ä¢ 1 (8 ounce) can pineapple chunks, drained, reserving the liquid\n",
      "‚Ä¢ 1 (16 ounce) can mandarin oranges, drained, reserving the liquid\n",
      "‚Ä¢ 12 cup cashew nuts\n",
      "\n",
      "üìù\n",
      "\n",
      "‚ñ™Ô∏é In a large skillet, toast the coconut over medium heat, until golden and crisp; set aside.\n",
      "‚ñ™Ô∏é Brown ground beef and garlic in the same skillet; drain well.\n",
      "‚ñ™Ô∏é Add salt, pepper lemon juice and soy sauce.\n",
      "‚ñ™Ô∏é In a small bowl combine the cornstarch with reserved pineapple and mandarin orange liquids; stir well until smooth then add to ground beef and cook over medium heat for 5 mins, stirring constantly, until mixture is thickened.\n",
      "‚ñ™Ô∏é Stir in the pineapple and mandarin oranges; cook 2-3 mins, or until thoroughly heated.\n",
      "‚ñ™Ô∏é Serve over noodles or rice, and sprinkle with more toasted coconut and cashew nuts.\n",
      "\n",
      "\n",
      "\n",
      "Recipe #7\n",
      "---------\n",
      "üìó Kombu Tea Grilled Chicken Thigh\n",
      "\n",
      "ü•ï\n",
      "\n",
      "‚Ä¢ 2 Chicken thighs\n",
      "‚Ä¢ 2 tsp Kombu tea\n",
      "‚Ä¢ 1 White pepper\n",
      "\n",
      "üìù\n",
      "\n",
      "‚ñ™Ô∏é Pierce the skin of the chicken with a fork or knife.\n",
      "‚ñ™Ô∏é Sprinkle with kombu tea evenly on both sides of the chicken, about 1 teaspoon per chicken thigh.\n",
      "‚ñ™Ô∏é Brown the skin side of the chicken first over high heat until golden brown.\n",
      "‚ñ™Ô∏é Sprinkle some pepper on the meat just before flipping over.\n",
      "‚ñ™Ô∏é Then brown the other side until golden brown.\n",
      "\n",
      "\n",
      "\n",
      "Recipe #8\n",
      "---------\n",
      "üìó Strawberry Rhubarb Dump Cake\n",
      "\n",
      "ü•ï\n",
      "\n",
      "‚Ä¢ 6 -8 cups fresh rhubarb, or\n",
      "‚Ä¢ 6 -8 cups frozen rhubarb, thawed\n",
      "‚Ä¢ 1 12 cups granulated sugar\n",
      "‚Ä¢ 6 ounces strawberry Jell-O gelatin dessert\n",
      "‚Ä¢ 1 white cake mix (2 layer size)\n",
      "‚Ä¢ 1 12 cups water\n",
      "‚Ä¢ 12 cup butter or 12 cup margarine, melted\n",
      "\n",
      "üìù\n",
      "\n",
      "‚ñ™Ô∏é Put ingredients in a buttered 9 x 12 x 2-inch pan in even layers in the order that they are given - DO NOT MIX.\n",
      "‚ñ™Ô∏é Bake in a 350 oven for 1 hour.\n",
      "\n",
      "\n",
      "\n",
      "Recipe #9\n",
      "---------\n",
      "üìó Yogurt Parfaits\n",
      "\n",
      "ü•ï\n",
      "\n",
      "‚Ä¢ 8 ounces, weight Light Fat Free Vanilla Yogurt (I Used Activia)\n",
      "‚Ä¢ 1 cup Fresh Sliced Strawberries\n",
      "‚Ä¢ 1/4 cups Low-fat Granola\n",
      "\n",
      "üìù\n",
      "\n",
      "‚ñ™Ô∏é Layer all ingredients in a serving dish.\n",
      "\n",
      "\n",
      "\n",
      "Recipe #10\n",
      "---------\n",
      "üìó Zucchini Nut Bread\n",
      "\n",
      "ü•ï\n",
      "\n",
      "‚Ä¢ 2 cups flour\n",
      "‚Ä¢ 1 tablespoon cinnamon\n",
      "‚Ä¢ 2 teaspoons baking soda\n",
      "‚Ä¢ 1 teaspoon salt\n",
      "‚Ä¢ 14 teaspoon baking powder\n",
      "‚Ä¢ 3 eggs\n",
      "‚Ä¢ 2 cups sugar\n",
      "‚Ä¢ 1 cup vegetable oil\n",
      "‚Ä¢ 1 tablespoon vanilla\n",
      "‚Ä¢ 2 cups grated raw zucchini\n",
      "‚Ä¢ 1 cup walnuts\n",
      "\n",
      "üìù\n",
      "\n",
      "‚ñ™Ô∏é Sift dry ingredients.\n",
      "‚ñ™Ô∏é beat eggs untill frothy, add sugar, oil and vanilla.\n",
      "‚ñ™Ô∏é Beat untillthick.\n",
      "‚ñ™Ô∏é Stir in zucchini.\n",
      "‚ñ™Ô∏é blend in sifted dry ingredients.\n",
      "‚ñ™Ô∏é Fold in nuts.\n",
      "‚ñ™Ô∏é pour in greased loaf pan and bake at 350 degrees for 1 1/2 hours.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for recipe_index, recipe_string in enumerate(dataset_stringified[:10]):\n",
    "    print('Recipe #{}\\n---------'.format(recipe_index + 1))\n",
    "    print(recipe_string)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ultimate-samoa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìó Cashew Chicken\n",
      "\n",
      "ü•ï\n",
      "\n",
      "‚Ä¢ 14 cup tapioca flour\n",
      "‚Ä¢ 12 teaspoon pepper\n",
      "‚Ä¢ 6 tablespoons coconut aminos or 6 tablespoons low sodium soy sauce\n",
      "‚Ä¢ 2 lbs chicken breasts (cut into 1.5-inch pieces) or 2 lbs chicken thighs (cut into 1.5-inch pieces)\n",
      "‚Ä¢ 4 tablespoons rice wine vinegar\n",
      "‚Ä¢ 4 tablespoons organic ketchup\n",
      "‚Ä¢ 12 teaspoon powdered ginger or 1 teaspoon fresh ginger\n",
      "‚Ä¢ 1 -2 tablespoon organic sugar\n",
      "‚Ä¢ 2 garlic cloves, minced\n",
      "‚Ä¢ 12 teaspoon red pepper flakes (optional)\n",
      "‚Ä¢ 2 carrots, sliced thin\n",
      "‚Ä¢ 2 stalks celery, sliced thin\n",
      "‚Ä¢ 1 medium zucchini, chopped\n",
      "‚Ä¢ 3 -4 green onions, sliced\n",
      "‚Ä¢ 2 -3 tablespoons coconut oil, divided\n",
      "‚Ä¢ 1 cup raw cashews\n",
      "\n",
      "üìù\n",
      "\n",
      "‚ñ™Ô∏é Melt 1.5 Tbs of the oil in a large skillet and saute all the veggies until almost soft; remove to a plate.\n",
      "‚ñ™Ô∏é Melt the remaining coconut oil in the skillet.\n",
      "‚ñ™Ô∏é Meanwhile, combine the tapioca flour and the pepper in a large Ziplock bag.\n",
      "‚ñ™Ô∏é Add chicken and shake to cover all pieces.\n",
      "‚ñ™Ô∏é Cook the chicken in the hot oil, over medium high heat, stirring often, until done.\n",
      "‚ñ™Ô∏é While chicken is cooking, combine remaining sauce ingredients in a small bowl.\n",
      "‚ñ™Ô∏é When chicken is done cooking, add the vegetables and the sauce back in, along with the cashews, and stir thoroughly.\n",
      "‚ñ™Ô∏é Warm through for a few minutes.\n",
      "‚ñ™Ô∏é Pour individual servings over cooked rice and serve.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset_stringified[50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "central-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_lengths = []\n",
    "for recipe_text in dataset_stringified:\n",
    "    recipes_lengths.append(len(recipe_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "exterior-number",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(recipes_lengths, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "binary-cancellation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(recipes_lengths, range=(0, 8000), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ready-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like a limit of 2000 characters for the recipes will cover 80+% cases.\n",
    "# We may try to train RNN with this maximum recipe length limit.\n",
    "MAX_RECIPE_LENGTH = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "decreased-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_recipes_by_length(recipe_test):\n",
    "    return len(recipe_test) <= MAX_RECIPE_LENGTH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "rising-commonwealth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size BEFORE filtering:  1029720\n",
      "Dataset size AFTER filtering:  965383\n",
      "Number of etiminated recipes:  64337\n"
     ]
    }
   ],
   "source": [
    "dataset_filtered = [recipe_text for recipe_text in dataset_stringified if filter_recipes_by_length(recipe_text)]\n",
    "\n",
    "print('Dataset size BEFORE filtering: ', len(dataset_stringified))\n",
    "print('Dataset size AFTER filtering: ', len(dataset_filtered))\n",
    "print('Number of etiminated recipes: ', len(dataset_stringified) - len(dataset_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "scientific-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filtered = dataset_filtered[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "egyptian-crowd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_RECIPE_LENGTH:  2000\n",
      "TOTAL_RECIPES_NUM:  10000\n"
     ]
    }
   ],
   "source": [
    "TOTAL_RECIPES_NUM = len(dataset_filtered)\n",
    "\n",
    "print('MAX_RECIPE_LENGTH: ', MAX_RECIPE_LENGTH)\n",
    "print('TOTAL_RECIPES_NUM: ', TOTAL_RECIPES_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "later-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicator of the end of the recipe.\n",
    "STOP_SIGN = '‚ê£'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "through-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    char_level=True,\n",
    "    filters='',\n",
    "    lower=False,\n",
    "    split=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "killing-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop word is not a part of recipes, but tokenizer must know about it as well.\n",
    "tokenizer.fit_on_texts([STOP_SIGN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "standing-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(dataset_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "affecting-success",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_words': None,\n",
       " 'filters': '',\n",
       " 'lower': False,\n",
       " 'split': '',\n",
       " 'char_level': True,\n",
       " 'oov_token': None,\n",
       " 'document_count': 10001,\n",
       " 'word_counts': '{\"\\\\u2423\": 1, \"\\\\ud83d\\\\udcd7\": 10000, \" \": 1469133, \"D\": 6334, \"i\": 415401, \"l\": 314028, \"y\": 62725, \"M\": 9119, \"a\": 499162, \"c\": 248214, \"r\": 400219, \"o\": 506824, \"n\": 441931, \"S\": 26296, \"d\": 257952, \"R\": 10313, \"e\": 761554, \"p\": 223858, \"\\\\n\": 252687, \"\\\\ud83e\\\\udd55\": 10000, \"\\\\u2022\": 88623, \"1\": 81614, \".\": 99096, \"b\": 117364, \"w\": 80820, \"m\": 151088, \"u\": 227009, \"A\": 14584, \"h\": 229155, \"s\": 393582, \"(\": 17532, \"4\": 21506, \")\": 17589, \"/\": 19238, \"2\": 46624, \"g\": 142995, \"3\": 20410, \"t\": 483090, \"v\": 58854, \"\\\\ud83d\\\\udcdd\": 10000, \"\\\\u25aa\": 94064, \"\\\\ufe0e\": 94064, \"C\": 23170, \"k\": 79125, \";\": 6084, \",\": 80619, \"B\": 14238, \"x\": 20215, \"T\": 12856, \"f\": 94457, \"6\": 4807, \"G\": 5163, \"z\": 10934, \"8\": 5613, \"q\": 5560, \"K\": 1864, \"E\": 4035, \"-\": 18782, \"O\": 5368, \"P\": 17673, \"F\": 9142, \"5\": 13657, \"0\": 15799, \"H\": 4560, \"j\": 9200, \"!\": 1435, \"\\'\": 2960, \"W\": 6059, \"J\": 1069, \"Y\": 1392, \"I\": 9330, \"9\": 2241, \"N\": 2380, \"X\": 135, \"L\": 5739, \"V\": 1694, \"U\": 1774, \"Z\": 296, \"&\": 1353, \"$\": 251, \"=\": 23, \"7\": 2218, \"\\\\\"\": 1146, \":\": 2319, \"Q\": 393, \"*\": 613, \"+\": 31, \"%\": 247, \"@\": 26, \"#\": 74, \"[\": 85, \"]\": 85, \"?\": 50, \"~\": 36, \"\\\\\\\\\": 1, \">\": 7, \"`\": 7, \"_\": 3, \"{\": 5, \"}\": 5, \"^\": 2}',\n",
       " 'word_docs': '{\"\\\\u2423\": 1, \")\": 6933, \"n\": 10000, \"2\": 9605, \"\\\\ud83d\\\\udcd7\": 10000, \"f\": 9804, \"6\": 3443, \"b\": 9946, \"c\": 9998, \"t\": 9998, \"d\": 9996, \"C\": 8343, \"v\": 9594, \"s\": 10000, \"4\": 8037, \".\": 9909, \"D\": 4275, \"h\": 9984, \"R\": 5510, \" \": 10000, \"A\": 6637, \"m\": 9970, \"\\\\ufe0e\": 10000, \",\": 9485, \"\\\\u25aa\": 10000, \"M\": 5419, \"S\": 8716, \"k\": 9717, \"a\": 10000, \"\\\\ud83d\\\\udcdd\": 10000, \"\\\\n\": 10000, \"u\": 9992, \";\": 2765, \"g\": 9962, \"x\": 7509, \"o\": 9999, \"/\": 6299, \"3\": 7842, \"l\": 9998, \"r\": 9999, \"y\": 9610, \"i\": 10000, \"(\": 6923, \"T\": 5755, \"\\\\ud83e\\\\udd55\": 10000, \"\\\\u2022\": 10000, \"w\": 9854, \"1\": 9913, \"e\": 10000, \"B\": 6763, \"p\": 9994, \"-\": 6938, \"z\": 4417, \"E\": 2275, \"q\": 3268, \"K\": 1333, \"G\": 3432, \"8\": 3841, \"!\": 1016, \"O\": 2808, \"F\": 5075, \"5\": 6495, \"0\": 6305, \"P\": 7532, \"H\": 3249, \"j\": 4752, \"\\'\": 2019, \"J\": 845, \"W\": 3866, \"Y\": 1141, \"I\": 5050, \"9\": 1625, \"X\": 121, \"N\": 1617, \"L\": 3523, \"V\": 1316, \"U\": 1379, \"Z\": 251, \"$\": 189, \"=\": 15, \"&\": 801, \"7\": 1803, \"\\\\\"\": 582, \":\": 1462, \"Q\": 347, \"*\": 304, \"+\": 26, \"%\": 201, \"@\": 20, \"#\": 53, \"[\": 39, \"]\": 40, \"?\": 42, \"~\": 24, \"\\\\\\\\\": 1, \">\": 5, \"`\": 6, \"_\": 3, \"{\": 4, \"}\": 4, \"^\": 1}',\n",
       " 'index_docs': '{\"1\": 10000, \"100\": 1, \"40\": 6933, \"6\": 10000, \"31\": 9605, \"49\": 10000, \"21\": 9804, \"64\": 3443, \"19\": 9946, \"13\": 9998, \"5\": 9998, \"11\": 9996, \"33\": 8343, \"30\": 9594, \"9\": 10000, \"34\": 8037, \"20\": 9909, \"56\": 4275, \"14\": 9984, \"48\": 5510, \"43\": 6637, \"17\": 9970, \"23\": 10000, \"27\": 9485, \"22\": 10000, \"55\": 5419, \"32\": 8716, \"28\": 9717, \"4\": 10000, \"51\": 10000, \"12\": 10000, \"15\": 9992, \"57\": 2765, \"18\": 9962, \"36\": 7509, \"3\": 9999, \"37\": 6299, \"35\": 7842, \"10\": 9998, \"8\": 9999, \"29\": 9610, \"7\": 10000, \"41\": 6923, \"46\": 5755, \"50\": 10000, \"24\": 10000, \"26\": 9854, \"25\": 9913, \"2\": 10000, \"44\": 6763, \"16\": 9994, \"38\": 6938, \"47\": 4417, \"66\": 2275, \"61\": 3268, \"72\": 1333, \"63\": 3432, \"60\": 3841, \"75\": 1016, \"62\": 2808, \"54\": 5075, \"45\": 6495, \"42\": 6305, \"39\": 7532, \"65\": 3249, \"53\": 4752, \"67\": 2019, \"79\": 845, \"58\": 3866, \"76\": 1141, \"52\": 5050, \"70\": 1625, \"85\": 121, \"68\": 1617, \"59\": 3523, \"74\": 1316, \"73\": 1379, \"82\": 251, \"83\": 189, \"93\": 15, \"77\": 801, \"71\": 1803, \"78\": 582, \"69\": 1462, \"81\": 347, \"80\": 304, \"91\": 26, \"84\": 201, \"92\": 20, \"88\": 53, \"86\": 39, \"87\": 40, \"89\": 42, \"90\": 24, \"101\": 1, \"94\": 5, \"95\": 6, \"98\": 3, \"96\": 4, \"97\": 4, \"99\": 1}',\n",
       " 'index_word': '{\"1\": \" \", \"2\": \"e\", \"3\": \"o\", \"4\": \"a\", \"5\": \"t\", \"6\": \"n\", \"7\": \"i\", \"8\": \"r\", \"9\": \"s\", \"10\": \"l\", \"11\": \"d\", \"12\": \"\\\\n\", \"13\": \"c\", \"14\": \"h\", \"15\": \"u\", \"16\": \"p\", \"17\": \"m\", \"18\": \"g\", \"19\": \"b\", \"20\": \".\", \"21\": \"f\", \"22\": \"\\\\u25aa\", \"23\": \"\\\\ufe0e\", \"24\": \"\\\\u2022\", \"25\": \"1\", \"26\": \"w\", \"27\": \",\", \"28\": \"k\", \"29\": \"y\", \"30\": \"v\", \"31\": \"2\", \"32\": \"S\", \"33\": \"C\", \"34\": \"4\", \"35\": \"3\", \"36\": \"x\", \"37\": \"/\", \"38\": \"-\", \"39\": \"P\", \"40\": \")\", \"41\": \"(\", \"42\": \"0\", \"43\": \"A\", \"44\": \"B\", \"45\": \"5\", \"46\": \"T\", \"47\": \"z\", \"48\": \"R\", \"49\": \"\\\\ud83d\\\\udcd7\", \"50\": \"\\\\ud83e\\\\udd55\", \"51\": \"\\\\ud83d\\\\udcdd\", \"52\": \"I\", \"53\": \"j\", \"54\": \"F\", \"55\": \"M\", \"56\": \"D\", \"57\": \";\", \"58\": \"W\", \"59\": \"L\", \"60\": \"8\", \"61\": \"q\", \"62\": \"O\", \"63\": \"G\", \"64\": \"6\", \"65\": \"H\", \"66\": \"E\", \"67\": \"\\'\", \"68\": \"N\", \"69\": \":\", \"70\": \"9\", \"71\": \"7\", \"72\": \"K\", \"73\": \"U\", \"74\": \"V\", \"75\": \"!\", \"76\": \"Y\", \"77\": \"&\", \"78\": \"\\\\\"\", \"79\": \"J\", \"80\": \"*\", \"81\": \"Q\", \"82\": \"Z\", \"83\": \"$\", \"84\": \"%\", \"85\": \"X\", \"86\": \"[\", \"87\": \"]\", \"88\": \"#\", \"89\": \"?\", \"90\": \"~\", \"91\": \"+\", \"92\": \"@\", \"93\": \"=\", \"94\": \">\", \"95\": \"`\", \"96\": \"{\", \"97\": \"}\", \"98\": \"_\", \"99\": \"^\", \"100\": \"\\\\u2423\", \"101\": \"\\\\\\\\\"}',\n",
       " 'word_index': '{\" \": 1, \"e\": 2, \"o\": 3, \"a\": 4, \"t\": 5, \"n\": 6, \"i\": 7, \"r\": 8, \"s\": 9, \"l\": 10, \"d\": 11, \"\\\\n\": 12, \"c\": 13, \"h\": 14, \"u\": 15, \"p\": 16, \"m\": 17, \"g\": 18, \"b\": 19, \".\": 20, \"f\": 21, \"\\\\u25aa\": 22, \"\\\\ufe0e\": 23, \"\\\\u2022\": 24, \"1\": 25, \"w\": 26, \",\": 27, \"k\": 28, \"y\": 29, \"v\": 30, \"2\": 31, \"S\": 32, \"C\": 33, \"4\": 34, \"3\": 35, \"x\": 36, \"/\": 37, \"-\": 38, \"P\": 39, \")\": 40, \"(\": 41, \"0\": 42, \"A\": 43, \"B\": 44, \"5\": 45, \"T\": 46, \"z\": 47, \"R\": 48, \"\\\\ud83d\\\\udcd7\": 49, \"\\\\ud83e\\\\udd55\": 50, \"\\\\ud83d\\\\udcdd\": 51, \"I\": 52, \"j\": 53, \"F\": 54, \"M\": 55, \"D\": 56, \";\": 57, \"W\": 58, \"L\": 59, \"8\": 60, \"q\": 61, \"O\": 62, \"G\": 63, \"6\": 64, \"H\": 65, \"E\": 66, \"\\'\": 67, \"N\": 68, \":\": 69, \"9\": 70, \"7\": 71, \"K\": 72, \"U\": 73, \"V\": 74, \"!\": 75, \"Y\": 76, \"&\": 77, \"\\\\\"\": 78, \"J\": 79, \"*\": 80, \"Q\": 81, \"Z\": 82, \"$\": 83, \"%\": 84, \"X\": 85, \"[\": 86, \"]\": 87, \"#\": 88, \"?\": 89, \"~\": 90, \"+\": 91, \"@\": 92, \"=\": 93, \">\": 94, \"`\": 95, \"{\": 96, \"}\": 97, \"_\": 98, \"^\": 99, \"\\\\u2423\": 100, \"\\\\\\\\\": 101}'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "clean-illinois",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCABULARY_SIZE:  102\n"
     ]
    }
   ],
   "source": [
    "# Adding +1 to take into account a special unassigned 0 index.\n",
    "# @see: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "VOCABULARY_SIZE = len(tokenizer.word_counts) + 1\n",
    "\n",
    "print('VOCABULARY_SIZE: ', VOCABULARY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "harmful-proxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.index_word[5])\n",
    "print(tokenizer.index_word[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ceramic-chuck",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "given-worker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' ', 'e', 'o', 'a', 't', 'n', 'i', 'r', 's', 'l', 'd', '\\n', 'c', 'h', 'u', 'p', 'm', 'g', 'b', '.', 'f', '‚ñ™', 'Ô∏é', '‚Ä¢', '1', 'w', ',', 'k', 'y', 'v', '2', 'S', 'C', '4', '3', 'x', '/', '-', 'P', ')', '(', '0', 'A', 'B', '5', 'T', 'z', 'R', 'üìó', 'ü•ï', 'üìù', 'I', 'j', 'F', 'M', 'D', ';', 'W', 'L', '8', 'q', 'O', 'G', '6', 'H', 'E', \"'\", 'N', ':', '9', '7', 'K', 'U', 'V', '!', 'Y', '&', '\"', 'J', '*', 'Q', 'Z', '$', '%', 'X', '[', ']', '#', '?', '~', '+', '@', '=', '>', '`', '{', '}', '_', '^', '‚ê£', '\\\\']\n"
     ]
    }
   ],
   "source": [
    "# For demo application we need to have an array of characters as vocabulary.\n",
    "js_vocabulary = tokenizer.sequences_to_texts([[word_index] for word_index in range(VOCABULARY_SIZE)])\n",
    "print([char for char in js_vocabulary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "general-benchmark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[49, 1, 29, 2, 9]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test proper conversion from text to indices.\n",
    "# This is needed for debugging a demo app.\n",
    "tokenizer.texts_to_sequences(['üìó yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "passive-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recipe_sequence_to_string(recipe_sequence):\n",
    "    recipe_stringified = tokenizer.sequences_to_texts([recipe_sequence])[0]\n",
    "    recipe_stringified = recipe_stringified.replace('   ', '_').replace(' ', '').replace('_', ' ')\n",
    "    print(recipe_stringified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "original-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_vectorized = tokenizer.texts_to_sequences(dataset_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "chronic-earth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized dataset size 10000\n"
     ]
    }
   ],
   "source": [
    "print('Vectorized dataset size', len(dataset_vectorized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "broad-discrimination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 1, 56, 7, 10, 10, 29, 1, 55, 4] ...\n"
     ]
    }
   ],
   "source": [
    "print(dataset_vectorized[0][:10], '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "experienced-vanilla",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_index_example:  [49, 1, 96, 44, 2, 7, 53, 7, 6, 14, 3, 9, 1, 56, 2, 1, 33, 3, 13, 3, 97, 1, 44, 8, 4, 47, 7, 10, 7, 4, 6, 1, 33, 3, 13, 3, 6, 15, 5, 1, 46, 8, 2, 4, 5, 9, 12, 12, 50, 12, 12, 24, 1, 25, 1, 41, 35, 70, 71, 1, 18, 40, 1, 13, 4, 6, 1, 13, 3, 6, 11, 2, 6, 9, 2, 11, 1, 17, 7, 10, 28, 12, 24, 1, 25, 42, 42, 1, 18, 1, 13, 3, 13, 3, 6, 15, 5, 1, 21, 10, 4, 28, 2, 9, 27, 1, 16, 10, 15, 9, 1, 2, 36, 5, 8, 4, 1, 21, 3, 8, 1, 8, 3, 10, 10, 7, 6, 18, 12, 24, 1, 25, 1, 5, 4, 19, 10, 2, 9, 16, 3, 3, 6, 1, 19, 15, 5, 5, 2, 8, 27, 1, 16, 10, 15, 9, 1, 2, 36, 5, 8, 4, 1, 21, 3, 8, 1, 8, 3, 10, 10, 7, 6, 18, 12, 24, 1, 25, 64, 1, 13, 10, 3, 30, 2, 9, 27, 1, 21, 3, 8, 1, 11, 2, 13, 3, 8, 4, 5, 7, 6, 18, 12, 12, 51, 12, 12, 22, 23, 1, 52, 6, 1, 4, 1, 16, 4, 6, 1, 4, 11, 11, 1, 5, 14, 2, 1, 13, 3, 6, 11, 2, 6, 9, 2, 11, 1, 17, 7, 10, 28, 27, 1, 25, 42, 42, 18, 1, 3, 21, 1, 13, 3, 13, 3, 6, 15, 5, 1, 21, 10, 4, 28, 2, 9, 1, 4, 6, 11, 1, 5, 14, 2, 1, 19, 15, 5, 5, 2, 8, 20, 12, 22, 23, 1, 68, 3, 26, 1, 5, 14, 2, 1, 21, 15, 6, 1, 19, 2, 18, 7, 6, 9, 75, 12, 22, 23, 1, 62, 30, 2, 8, 1, 17, 2, 11, 7, 15, 17, 1, 14, 2, 4, 5, 1, 9, 5, 4, 8, 5, 1, 9, 5, 7, 8, 8, 7, 6, 18, 20, 12, 22, 23, 1, 43, 6, 11, 1, 28, 2, 2, 16, 1, 9, 5, 7, 8, 8, 7, 6, 18, 1, 15, 6, 5, 7, 10, 1, 5, 14, 2, 1, 17, 7, 36, 5, 15, 8, 2, 1, 5, 14, 7, 13, 28, 2, 6, 9, 1, 4, 6, 11, 1, 29, 3, 15, 1, 13, 4, 6, 1, 9, 2, 2, 1, 5, 14, 2, 1, 19, 3, 5, 5, 3, 17, 1, 3, 21, 1, 5, 14, 2, 1, 16, 4, 6, 1, 21, 3, 8, 1, 4, 1, 18, 3, 3, 11, 1, 21, 2, 26, 1, 9, 2, 13, 3, 6, 11, 9, 1, 19, 2, 21, 3, 8, 2, 1, 5, 14, 2, 1, 17, 7, 36, 5, 15, 8, 2, 1, 10, 2, 30, 2, 10, 9, 1, 3, 15, 5, 1, 4, 18, 4, 7, 6, 20, 12, 22, 23, 1, 46, 14, 7, 9, 1, 7, 9, 1, 8, 2, 4, 10, 10, 29, 1, 7, 17, 16, 3, 8, 5, 4, 6, 5, 20, 12, 22, 23, 1, 46, 14, 7, 9, 1, 16, 8, 3, 13, 2, 9, 9, 1, 9, 14, 3, 15, 10, 11, 1, 5, 4, 28, 2, 1, 4, 5, 1, 10, 2, 4, 9, 5, 1, 64, 38, 71, 1, 17, 7, 6, 27, 1, 11, 3, 6, 5, 1, 8, 15, 9, 14, 1, 7, 5, 1, 3, 8, 1, 7, 5, 1, 26, 3, 6, 5, 1, 19, 2, 1, 5, 14, 2, 1, 8, 7, 18, 14, 5, 1, 13, 3, 6, 9, 7, 9, 5, 2, 6, 13, 29, 1, 5, 3, 1, 8, 3, 10, 10, 1, 7, 6, 5, 3, 1, 19, 4, 10, 10, 9, 20, 12, 22, 23, 1, 59, 2, 4, 30, 2, 1, 7, 5, 1, 5, 3, 1, 13, 3, 3, 10, 27, 1, 4, 19, 3, 15, 5, 1, 25, 45, 17, 7, 6, 1, 3, 8, 1, 2, 6, 3, 15, 18, 14, 1, 9, 3, 1, 5, 14, 4, 5, 1, 7, 5, 1, 7, 9, 1, 13, 3, 3, 10, 1, 5, 3, 1, 14, 4, 6, 11, 10, 2, 1, 4, 6, 11, 1, 7, 5, 1, 14, 4, 9, 1, 14, 4, 8, 11, 2, 6, 2, 11, 1, 15, 16, 1, 4, 1, 10, 7, 5, 5, 10, 2, 20, 12, 22, 23, 1, 63, 8, 4, 19, 1, 5, 14, 2, 1, 21, 10, 4, 28, 2, 9, 1, 29, 3, 15, 1, 14, 4, 11, 1, 8, 2, 9, 2, 8, 30, 2, 11, 1, 21, 3, 8, 1, 8, 3, 10, 10, 7, 6, 18, 20, 12, 22, 23, 1, 76, 3, 15, 1, 13, 4, 6, 1, 11, 3, 1, 31, 1, 5, 14, 7, 6, 18, 9, 1, 14, 2, 8, 2, 69, 1, 25, 40, 1, 73, 9, 2, 1, 5, 14, 2, 17, 1, 4, 9, 1, 5, 14, 2, 29, 1, 4, 8, 2, 1, 5, 3, 1, 8, 3, 10, 10, 1, 3, 8, 1, 31, 40, 1, 44, 10, 7, 5, 47, 1, 5, 14, 2, 17, 1, 9, 3, 1, 5, 14, 4, 5, 1, 5, 14, 2, 29, 1, 4, 8, 2, 1, 9, 15, 16, 2, 8, 1, 21, 7, 6, 2, 20, 12, 22, 23, 1, 52, 1, 19, 10, 7, 5, 47, 2, 11, 1, 5, 14, 2, 17, 1, 4, 9, 1, 52, 1, 10, 7, 28, 2, 1, 5, 14, 2, 1, 3, 15, 5, 9, 7, 11, 2, 1, 5, 2, 36, 5, 15, 8, 2, 1, 5, 3, 1, 19, 2, 1, 9, 3, 21, 5, 20, 12, 22, 23, 1, 44, 15, 5, 1, 7, 5, 1, 7, 9, 1, 5, 3, 5, 4, 10, 10, 29, 1, 15, 16, 1, 5, 3, 1, 29, 3, 15, 1, 7, 21, 1, 29, 3, 15, 1, 11, 2, 13, 7, 11, 2, 1, 5, 3, 1, 11, 3, 1, 5, 14, 7, 9, 20, 12, 22, 23, 1, 33, 3, 4, 5, 1, 29, 3, 15, 8, 1, 14, 4, 6, 11, 9, 1, 7, 6, 1, 4, 1, 10, 7, 5, 5, 10, 2, 1, 19, 15, 5, 5, 2, 8, 1, 41, 53, 15, 9, 5, 1, 9, 3, 1, 5, 14, 4, 5, 1, 5, 14, 2, 1, 17, 7, 36, 5, 15, 8, 2, 1, 11, 3, 2, 9, 6, 5, 1, 9, 5, 7, 13, 28, 40, 1, 4, 6, 11, 1, 9, 5, 4, 8, 5, 1, 17, 4, 28, 7, 6, 18, 1, 29, 3, 15, 8, 1, 19, 4, 10, 10, 9, 20, 12, 22, 23, 1, 52, 1, 10, 7, 28, 2, 1, 17, 7, 6, 2, 1, 5, 14, 2, 1, 9, 7, 47, 2, 1, 3, 21, 1, 4, 1, 10, 7, 5, 5, 10, 2, 1, 9, 17, 4, 10, 10, 2, 8, 1, 5, 14, 4, 6, 1, 4, 1, 17, 2, 4, 9, 15, 8, 7, 6, 18, 1, 5, 4, 19, 10, 2, 9, 16, 3, 3, 6, 20, 12, 22, 23, 1, 62, 6, 13, 2, 1, 4, 10, 10, 1, 8, 3, 10, 10, 2, 11, 1, 3, 15, 5, 1, 16, 15, 5, 1, 3, 6, 2, 1, 13, 10, 3, 30, 2, 1, 7, 6, 1, 5, 14, 2, 1, 17, 7, 11, 10, 2, 1, 21, 3, 8, 1, 11, 2, 13, 3, 8, 4, 5, 7, 3, 6, 20, 12, 22, 23, 1, 46, 14, 7, 9, 1, 7, 9, 1, 5, 8, 4, 11, 7, 5, 7, 3, 6, 4, 10, 1, 4, 6, 11, 1, 21, 3, 8, 1, 11, 2, 13, 3, 8, 4, 5, 7, 3, 6, 20, 12, 22, 23, 1, 48, 2, 17, 3, 30, 2, 1, 7, 5, 1, 19, 2, 21, 3, 8, 2, 1, 2, 4, 5, 7, 6, 18, 1, 4, 6, 11, 1, 7, 5, 1, 11, 3, 2, 9, 1, 10, 2, 4, 30, 2, 1, 4, 1, 6, 7, 13, 2, 1, 5, 4, 9, 5, 2, 20, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nenad/faks/SIAP/venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:87: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "max_index_example = np.max(dataset_vectorized)\n",
    "\n",
    "print('max_index_example: ', max_index_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "arabic-martin",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìó Dilly Macaroni Salad Recipe\n",
      "\n",
      "ü•ï\n",
      "\n",
      "‚Ä¢ 1 c. elbow macaroni\n",
      "‚Ä¢ 1 c. cubed American cheese (4 ounce.)\n",
      "‚Ä¢ 1/2 c. sliced celery\n",
      "‚Ä¢ 1/2 c. minced green pepper\n",
      "‚Ä¢ 3 tbsp. minced pimento\n",
      "‚Ä¢ 1/2 c. mayonnaise or possibly salad dressing\n",
      "‚Ä¢ 1 tbsp. vinegar\n",
      "‚Ä¢ 3/4 teaspoon salt\n",
      "‚Ä¢ 1/2 teaspoon dry dill weed\n",
      "\n",
      "üìù\n",
      "\n",
      "‚ñ™Ô∏é Cook macaroni according to package directions; drain well.\n",
      "‚ñ™Ô∏é Cold.\n",
      "‚ñ™Ô∏é Combine macaroni, cheese cubes, celery, green pepper and pimento.\n",
      "‚ñ™Ô∏é Blend together mayonnaise or possibly salad dressing, vinegar, salt and dill weed; add in to macaroni mix.\n",
      "‚ñ™Ô∏é Toss lightly.\n",
      "‚ñ™Ô∏é Cover and refrigeratewell.\n",
      "‚ñ™Ô∏é Serve salad in lettuce lined bowl if you like.\n",
      "‚ñ™Ô∏é Makes 6 servings.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recipe_sequence_to_string(dataset_vectorized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "casual-lending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe #1 length: 659\n",
      "Recipe #2 length: 600\n",
      "Recipe #3 length: 654\n",
      "Recipe #4 length: 389\n",
      "Recipe #5 length: 1008\n",
      "Recipe #6 length: 443\n",
      "Recipe #7 length: 423\n",
      "Recipe #8 length: 197\n",
      "Recipe #9 length: 499\n",
      "Recipe #10 length: 1788\n"
     ]
    }
   ],
   "source": [
    "for recipe_index, recipe in enumerate(dataset_vectorized[:10]):\n",
    "    print('Recipe #{} length: {}'.format(recipe_index + 1, len(recipe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "incorrect-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_vectorized_padded_without_stops = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    dataset_vectorized,\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    "    # We use -1 here and +1 in the next step to make sure that all recipes will have at least 1 stops\n",
    "    # sign at the end, since each sequence will be shifted and truncated afterwards (to generate X and Y sequences).\n",
    "    maxlen=MAX_RECIPE_LENGTH-1,\n",
    "    value=tokenizer.texts_to_sequences([STOP_SIGN])[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "humanitarian-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_vectorized_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    dataset_vectorized_padded_without_stops,\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    "    maxlen=MAX_RECIPE_LENGTH+1,\n",
    "    value=tokenizer.texts_to_sequences([STOP_SIGN])[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "intensive-youth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe #0 length: 2001\n",
      "Recipe #1 length: 2001\n",
      "Recipe #2 length: 2001\n",
      "Recipe #3 length: 2001\n",
      "Recipe #4 length: 2001\n",
      "Recipe #5 length: 2001\n",
      "Recipe #6 length: 2001\n",
      "Recipe #7 length: 2001\n",
      "Recipe #8 length: 2001\n",
      "Recipe #9 length: 2001\n"
     ]
    }
   ],
   "source": [
    "for recipe_index, recipe in enumerate(dataset_vectorized_padded[:10]):\n",
    "    print('Recipe #{} length: {}'.format(recipe_index, len(recipe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bacterial-comparative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìó Dilly Macaroni Salad Recipe\n",
      "\n",
      "ü•ï\n",
      "\n",
      "‚Ä¢ 1 c. elbow macaroni\n",
      "‚Ä¢ 1 c. cubed American cheese (4 ounce.)\n",
      "‚Ä¢ 1/2 c. sliced celery\n",
      "‚Ä¢ 1/2 c. minced green pepper\n",
      "‚Ä¢ 3 tbsp. minced pimento\n",
      "‚Ä¢ 1/2 c. mayonnaise or possibly salad dressing\n",
      "‚Ä¢ 1 tbsp. vinegar\n",
      "‚Ä¢ 3/4 teaspoon salt\n",
      "‚Ä¢ 1/2 teaspoon dry dill weed\n",
      "\n",
      "üìù\n",
      "\n",
      "‚ñ™Ô∏é Cook macaroni according to package directions; drain well.\n",
      "‚ñ™Ô∏é Cold.\n",
      "‚ñ™Ô∏é Combine macaroni, cheese cubes, celery, green pepper and pimento.\n",
      "‚ñ™Ô∏é Blend together mayonnaise or possibly salad dressing, vinegar, salt and dill weed; add in to macaroni mix.\n",
      "‚ñ™Ô∏é Toss lightly.\n",
      "‚ñ™Ô∏é Cover and refrigeratewell.\n",
      "‚ñ™Ô∏é Serve salad in lettuce lined bowl if you like.\n",
      "‚ñ™Ô∏é Makes 6 servings.\n",
      "‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£\n"
     ]
    }
   ],
   "source": [
    "recipe_sequence_to_string(dataset_vectorized_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fossil-nelson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_index_example:  101\n"
     ]
    }
   ],
   "source": [
    "max_index_example = np.max(dataset_vectorized_padded)\n",
    "\n",
    "print('max_index_example: ', max_index_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "competent-archives",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (2001,), types: tf.int32>\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(dataset_vectorized_padded)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "suspended-writer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw recipe:\n",
      " [ 49   1  56 ... 100 100 100] \n",
      "\n",
      "\n",
      "\n",
      "Stringified recipe:\n",
      "\n",
      "üìó Dilly Macaroni Salad Recipe\n",
      "\n",
      "ü•ï\n",
      "\n",
      "‚Ä¢ 1 c. elbow macaroni\n",
      "‚Ä¢ 1 c. cubed American cheese (4 ounce.)\n",
      "‚Ä¢ 1/2 c. sliced celery\n",
      "‚Ä¢ 1/2 c. minced green pepper\n",
      "‚Ä¢ 3 tbsp. minced pimento\n",
      "‚Ä¢ 1/2 c. mayonnaise or possibly salad dressing\n",
      "‚Ä¢ 1 tbsp. vinegar\n",
      "‚Ä¢ 3/4 teaspoon salt\n",
      "‚Ä¢ 1/2 teaspoon dry dill weed\n",
      "\n",
      "üìù\n",
      "\n",
      "‚ñ™Ô∏é Cook macaroni according to package directions; drain well.\n",
      "‚ñ™Ô∏é Cold.\n",
      "‚ñ™Ô∏é Combine macaroni, cheese cubes, celery, green pepper and pimento.\n",
      "‚ñ™Ô∏é Blend together mayonnaise or possibly salad dressing, vinegar, salt and dill weed; add in to macaroni mix.\n",
      "‚ñ™Ô∏é Toss lightly.\n",
      "‚ñ™Ô∏é Cover and refrigeratewell.\n",
      "‚ñ™Ô∏é Serve salad in lettuce lined bowl if you like.\n",
      "‚ñ™Ô∏é Makes 6 servings.\n",
      "‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£‚ê£\n"
     ]
    }
   ],
   "source": [
    "for recipe in dataset.take(1):\n",
    "    print('Raw recipe:\\n', recipe.numpy(), '\\n\\n\\n')\n",
    "    print('Stringified recipe:\\n')\n",
    "    recipe_sequence_to_string(recipe.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "iraqi-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(recipe):\n",
    "    input_text = recipe[:-1]\n",
    "    target_text = recipe[1:]\n",
    "    \n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "subject-pantyhose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((2000,), (2000,)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "dataset_targeted = dataset.map(split_input_target)\n",
    "\n",
    "print(dataset_targeted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "discrete-luxury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence size: 2000\n",
      "Target sequence size: 2000\n",
      "\n",
      "Input:   'üìó   D i l l y   M a c a r o n i   S a l a d   R e c i p e \\n \\n ü•ï \\n \\n ‚Ä¢   1   c .   e l b o w   m a c'\n",
      "Target:  '  D i l l y   M a c a r o n i   S a l a d   R e c i p e \\n \\n ü•ï \\n \\n ‚Ä¢   1   c .   e l b o w   m a c a'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset_targeted.take(1):\n",
    "    print('Input sequence size:', repr(len(input_example.numpy())))\n",
    "    print('Target sequence size:', repr(len(target_example.numpy())))\n",
    "    print()\n",
    "    \n",
    "    input_stringified = tokenizer.sequences_to_texts([input_example.numpy()[:50]])[0]\n",
    "    target_stringified = tokenizer.sequences_to_texts([target_example.numpy()[:50]])[0]\n",
    "    \n",
    "    print('Input:  ', repr(''.join(input_stringified)))\n",
    "    print('Target: ', repr(''.join(target_stringified)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "entitled-absolute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  1\n",
      "  input: 49 ('üìó')\n",
      "  expected output: 1 (' ')\n",
      "Step  2\n",
      "  input: 1 (' ')\n",
      "  expected output: 56 ('D')\n",
      "Step  3\n",
      "  input: 56 ('D')\n",
      "  expected output: 7 ('i')\n",
      "Step  4\n",
      "  input: 7 ('i')\n",
      "  expected output: 10 ('l')\n",
      "Step  5\n",
      "  input: 10 ('l')\n",
      "  expected output: 10 ('l')\n",
      "Step  6\n",
      "  input: 10 ('l')\n",
      "  expected output: 29 ('y')\n",
      "Step  7\n",
      "  input: 29 ('y')\n",
      "  expected output: 1 (' ')\n",
      "Step  8\n",
      "  input: 1 (' ')\n",
      "  expected output: 55 ('M')\n",
      "Step  9\n",
      "  input: 55 ('M')\n",
      "  expected output: 4 ('a')\n",
      "Step 10\n",
      "  input: 4 ('a')\n",
      "  expected output: 13 ('c')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:10], target_example[:10])):\n",
    "    print('Step {:2d}'.format(i + 1))\n",
    "    print('  input: {} ({:s})'.format(input_idx, repr(tokenizer.sequences_to_texts([[input_idx.numpy()]])[0])))\n",
    "    print('  expected output: {} ({:s})'.format(target_idx, repr(tokenizer.sequences_to_texts([[target_idx.numpy()]])[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "muslim-commonwealth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((2000,), (2000,)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "print(dataset_targeted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "instant-vietnamese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL_RECIPES_NUM:  10000\n",
      "MAX_RECIPE_LENGTH:  2000\n",
      "VOCABULARY_SIZE:  102\n"
     ]
    }
   ],
   "source": [
    "print('TOTAL_RECIPES_NUM: ', TOTAL_RECIPES_NUM)\n",
    "print('MAX_RECIPE_LENGTH: ', MAX_RECIPE_LENGTH)\n",
    "print('VOCABULARY_SIZE: ', VOCABULARY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "communist-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size.\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset (TF data is designed to work\n",
    "# with possibly infinite sequences, so it doesn't attempt to shuffle\n",
    "# the entire sequence in memory. Instead, it maintains a buffer in\n",
    "# which it shuffles elements).\n",
    "SHUFFLE_BUFFER_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "applicable-signal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RepeatDataset shapes: ((64, 2000), (64, 2000)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "dataset_train = dataset_targeted \\\n",
    "  .shuffle(SHUFFLE_BUFFER_SIZE) \\\n",
    "  .batch(BATCH_SIZE, drop_remainder=True) \\\n",
    "  .repeat()\n",
    "\n",
    "print(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dominican-bridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st batch: input_text: tf.Tensor(\n",
      "[[ 49   1  32 ... 100 100 100]\n",
      " [ 49   1  43 ... 100 100 100]\n",
      " [ 49   1  33 ... 100 100 100]\n",
      " ...\n",
      " [ 49   1  39 ... 100 100 100]\n",
      " [ 49   1   9 ... 100 100 100]\n",
      " [ 49   1  62 ... 100 100 100]], shape=(64, 2000), dtype=int32)\n",
      "\n",
      "1st batch: target_text: tf.Tensor(\n",
      "[[  1  32  15 ... 100 100 100]\n",
      " [  1  43  10 ... 100 100 100]\n",
      " [  1  33   3 ... 100 100 100]\n",
      " ...\n",
      " [  1  39   4 ... 100 100 100]\n",
      " [  1   9   2 ... 100 100 100]\n",
      " [  1  62   8 ... 100 100 100]], shape=(64, 2000), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for input_text, target_text in dataset_train.take(1):\n",
    "    print('1st batch: input_text:', input_text)\n",
    "    print()\n",
    "    print('1st batch: target_text:', target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "controversial-profile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp_input_array shape: (2, 8)\n",
      "tmp_input_array:\n",
      "[[2 5 0 1 1 5 0 9]\n",
      " [4 1 5 5 8 3 9 4]]\n",
      "\n",
      "tmp_output_array shape: (2, 8, 5)\n",
      "tmp_output_array:\n",
      "[[[-0.03935884 -0.02856649  0.03949095  0.01182967  0.00201129]\n",
      "  [ 0.01034914 -0.03823736  0.0057352   0.02447255  0.02012812]\n",
      "  [-0.00740807  0.01597485 -0.01953821 -0.04140968  0.04290983]\n",
      "  [ 0.02257681  0.04394804  0.01836641 -0.02136711  0.04009095]\n",
      "  [ 0.02257681  0.04394804  0.01836641 -0.02136711  0.04009095]\n",
      "  [ 0.01034914 -0.03823736  0.0057352   0.02447255  0.02012812]\n",
      "  [-0.00740807  0.01597485 -0.01953821 -0.04140968  0.04290983]\n",
      "  [-0.04128193 -0.01630398  0.0393586  -0.03839464  0.02939672]]\n",
      "\n",
      " [[-0.00010477 -0.02054576  0.02029934  0.03907696 -0.02464532]\n",
      "  [ 0.02257681  0.04394804  0.01836641 -0.02136711  0.04009095]\n",
      "  [ 0.01034914 -0.03823736  0.0057352   0.02447255  0.02012812]\n",
      "  [ 0.01034914 -0.03823736  0.0057352   0.02447255  0.02012812]\n",
      "  [-0.02263125 -0.01996081  0.02445222  0.00480532 -0.00691847]\n",
      "  [ 0.01076756  0.01211058 -0.04355038 -0.02172204  0.04682405]\n",
      "  [-0.04128193 -0.01630398  0.0393586  -0.03839464  0.02939672]\n",
      "  [-0.00010477 -0.02054576  0.02029934  0.03907696 -0.02464532]]]\n"
     ]
    }
   ],
   "source": [
    "# Let's do a quick detour and see how Embeding layer works.\n",
    "# It takes several char indices sequences (batch) as an input.\n",
    "# It encodes every character of every sequence to a vector of tmp_embeding_size length.\n",
    "tmp_vocab_size = 10\n",
    "tmp_embeding_size = 5\n",
    "tmp_input_length = 8\n",
    "tmp_batch_size = 2\n",
    "\n",
    "tmp_model = tf.keras.models.Sequential()\n",
    "tmp_model.add(tf.keras.layers.Embedding(\n",
    "  input_dim=tmp_vocab_size,\n",
    "  output_dim=tmp_embeding_size,\n",
    "  input_length=tmp_input_length\n",
    "))\n",
    "# The model will take as input an integer matrix of size (batch, input_length).\n",
    "# The largest integer (i.e. word index) in the input should be no larger than 9 (tmp_vocab_size).\n",
    "# Now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
    "tmp_input_array = np.random.randint(\n",
    "  low=0,\n",
    "  high=tmp_vocab_size,\n",
    "  size=(tmp_batch_size, tmp_input_length)\n",
    ")\n",
    "tmp_model.compile('rmsprop', 'mse')\n",
    "tmp_output_array = tmp_model.predict(tmp_input_array)\n",
    "\n",
    "print('tmp_input_array shape:', tmp_input_array.shape)\n",
    "print('tmp_input_array:')\n",
    "print(tmp_input_array)\n",
    "print()\n",
    "print('tmp_output_array shape:', tmp_output_array.shape)\n",
    "print('tmp_output_array:')\n",
    "print(tmp_output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "sudden-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars.\n",
    "vocab_size = VOCABULARY_SIZE\n",
    "\n",
    "# The embedding dimension.\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units.\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "surprising-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_1(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        batch_input_shape=[batch_size, None]\n",
    "    ))\n",
    "\n",
    "    model.add(tf.keras.layers.LSTM(\n",
    "        units=rnn_units,\n",
    "        return_sequences=True,\n",
    "        stateful=True,\n",
    "        recurrent_initializer=tf.keras.initializers.GlorotNormal()\n",
    "    ))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(vocab_size))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "above-mason",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (64, None, 256)           26112     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 102)           104550    \n",
      "=================================================================\n",
      "Total params: 5,377,638\n",
      "Trainable params: 5,377,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = build_model_1(vocab_size, embedding_dim, rnn_units, BATCH_SIZE)\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "removed-profile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 2000, 102) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset_train.take(1):\n",
    "    example_batch_predictions = model_1(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "experimental-livestock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the 1st letter of the batch 1st sequense:\n",
      "tf.Tensor(\n",
      "[ 4.4282683e-04 -1.8786700e-03  1.6066602e-03  6.6993264e-03\n",
      "  2.9222865e-04  3.9959676e-03  9.6368417e-03  1.5699025e-03\n",
      "  4.2908238e-03  1.1954735e-03  2.8902437e-03 -1.4440452e-03\n",
      "  3.2361040e-03  6.0781522e-04  1.0570972e-03 -4.5267330e-03\n",
      " -6.4871153e-03 -6.0083661e-03  1.7645801e-03  5.5293255e-03\n",
      " -4.7595273e-03  9.9675287e-04  1.8931022e-03  5.0927227e-04\n",
      " -7.2629564e-03 -8.3387445e-04  3.5099844e-03  5.5061225e-03\n",
      "  4.5769275e-03  3.2508723e-04 -4.0296116e-03 -5.0898612e-04\n",
      " -1.7637792e-03 -4.6178214e-03 -1.6380239e-03  2.2367893e-04\n",
      "  4.7997851e-03 -4.7538616e-03 -3.2069571e-03 -7.5746793e-04\n",
      " -5.8040796e-03  6.5190056e-03 -8.2996329e-03 -1.0872615e-03\n",
      "  4.3292101e-03  6.5282569e-05  8.1932433e-03  6.6309521e-04\n",
      "  3.1817879e-03  6.0632988e-03  1.9224128e-04 -8.8535435e-04\n",
      "  6.2244027e-03  5.1239529e-04  1.2197646e-03  1.6033433e-03\n",
      "  2.2098075e-03  3.7731442e-03 -5.2443929e-03 -3.9289459e-03\n",
      "  2.4653403e-03 -1.7840873e-03  6.7323707e-03 -2.3377137e-03\n",
      " -7.1714269e-03 -2.2719402e-03  5.5959290e-03 -2.8528699e-03\n",
      " -8.6547434e-03 -2.5570998e-04 -3.9769039e-03  6.2408671e-04\n",
      "  3.3551585e-03  2.3277728e-03  2.0964353e-03  1.0011337e-03\n",
      " -7.7543611e-04 -4.6335324e-03 -6.7576431e-03  3.4870768e-03\n",
      "  5.0659128e-04  1.1201889e-03  1.0617275e-03  2.7468801e-03\n",
      "  2.2520705e-03  1.9552279e-04 -7.1610062e-04 -2.5551775e-03\n",
      " -2.8648248e-03  1.6891179e-03 -5.5742902e-03  3.9559221e-03\n",
      " -2.4038616e-03 -4.6126563e-03  9.6086826e-04 -6.8208517e-04\n",
      " -4.6240231e-03 -1.2050041e-03  9.3612296e-04 -3.9054593e-04\n",
      "  1.4694843e-03  2.8945792e-03], shape=(102,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('Prediction for the 1st letter of the batch 1st sequense:')\n",
    "print(example_batch_predictions[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "musical-boring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 1 2 2 1]], shape=(1, 5), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Quick overview of how tf.random.categorical() works.\n",
    "\n",
    "# logits is 2-D Tensor with shape [batch_size, num_classes].\n",
    "# Each slice [i, :] represents the unnormalized log-probabilities for all classes.\n",
    "# In the example below we say that the probability for class \"0\" is low but the\n",
    "# probability for class \"2\" is much higher.\n",
    "tmp_logits = [\n",
    "  [-0.95, 0, 0.95],\n",
    "];\n",
    "\n",
    "# Let's generate 5 samples. Each sample is a class index. Class probabilities \n",
    "# are being taken into account (we expect to see more samples of class \"2\").\n",
    "tmp_samples = tf.random.categorical(\n",
    "    logits=tmp_logits,\n",
    "    num_samples=5\n",
    ")\n",
    "\n",
    "print(tmp_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "essential-ballot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2000, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(\n",
    "    logits=example_batch_predictions[0],\n",
    "    num_samples=1\n",
    ")\n",
    "\n",
    "sampled_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "amber-miller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.squeeze(\n",
    "    input=sampled_indices,\n",
    "    axis=-1\n",
    ").numpy()\n",
    "\n",
    "sampled_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "partial-musician",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5,  87,  10,  32,  32,  19,  42,  29,  14,  70,  39,  60,  28,\n",
       "        10,  48,  31,  51,   3,  66,  24,  24,  53,  71,  36,  42,  90,\n",
       "         5,  33,  62,   8,  16,  96,  53,  42,  13,  98,  51, 100,  24,\n",
       "        99,  13,  38,  51,  19,  73,  95,  80,  28,  61,   6,  27,  92,\n",
       "        49,  17,  72,  85,  39,  36,  28,  27,  36,  74,  10,  40,  57,\n",
       "        22,  68,  10,  70,   2, 100,  51,  40,  63,  62,  51,  51,  93,\n",
       "        34,  67,  55,  33,   2,   4,  99,  80,  35,  14,  45,  17,  31,\n",
       "        28,  55,  33,  33,  71,  28,  50,  26,  14])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "formal-induction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " 'üìó   B r u s s e l s   S p r o u t s   a l a   A n g e l a \\n \\n ü•ï \\n \\n ‚Ä¢   6   s l i c e s   b a c o n'\n",
      "\n",
      "Next char prediction:\n",
      " 't ] l S S b 0 y h 9 P 8 k l R 2 üìù o E ‚Ä¢ ‚Ä¢ j 7 x 0 ~ t C O r p { j 0 c _ üìù ‚ê£ ‚Ä¢ ^ c - üìù b U ` * k q n'\n"
     ]
    }
   ],
   "source": [
    "print('Input:\\n', repr(''.join(tokenizer.sequences_to_texts([input_example_batch[0].numpy()[:50]]))))\n",
    "print()\n",
    "print('Next char prediction:\\n', repr(''.join(tokenizer.sequences_to_texts([sampled_indices[:50]]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "amazing-contest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 10, 102) # (batch_size, sequence_length, vocab_size)\n",
      "\n",
      "Custom length input: \n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch_custom, target_example_batch_custom in dataset_train.take(1):\n",
    "    random_input = np.zeros(shape=(BATCH_SIZE, 10))\n",
    "    example_batch_predictions_custom = model_1(random_input)\n",
    "    print('Prediction shape: ', example_batch_predictions_custom.shape, \"# (batch_size, sequence_length, vocab_size)\\n\")\n",
    "    print('Custom length input: ')\n",
    "    print(random_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "central-cowboy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 2000, 102)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss.shape:       (64, 2000)\n",
      "scalar_loss:       4.627686\n"
     ]
    }
   ],
   "source": [
    "# An objective function.\n",
    "# The function is any callable with the signature scalar_loss = fn(y_true, y_pred).\n",
    "def loss(labels, logits):\n",
    "    entropy = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "      y_true=labels,\n",
    "      y_pred=logits,\n",
    "      from_logits=True\n",
    "    )\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss.shape:      \", example_batch_loss.shape)\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "blind-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model_1.compile(\n",
    "    optimizer=adam_optimizer,\n",
    "    loss=loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "unexpected-static",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved.\n",
    "checkpoint_dir = 'tmp/checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "occasional-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_latest_checkpoint(zip_only=True):\n",
    "    latest_checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    latest_checkpoint_name = os.path.split(latest_checkpoint_path)[-1]\n",
    "    latest_checkpoint_zip_name = latest_checkpoint_name + '.zip'\n",
    "    \n",
    "    print('latest_checkpoint_path: ', latest_checkpoint_path)\n",
    "    print('latest_checkpoint_name: ', latest_checkpoint_name)\n",
    "    print('---\\n')\n",
    "\n",
    "    print('Checkpoint files:')\n",
    "    with zipfile.ZipFile(latest_checkpoint_zip_name, mode='w') as zip_obj:\n",
    "        for folder_name, subfolders, filenames in os.walk(checkpoint_dir):\n",
    "            for filename in filenames:\n",
    "                if filename.startswith(latest_checkpoint_name):\n",
    "                        print('  - ' + filename)\n",
    "                        file_path = os.path.join(folder_name, filename)\n",
    "                        zip_obj.write(file_path, os.path.basename(file_path))\n",
    "    print('---\\n')\n",
    "    print('Zipped to: ', latest_checkpoint_zip_name)\n",
    "\n",
    "    if not zip_only:\n",
    "        files.download(latest_checkpoint_zip_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "through-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_weights_from_latest_checkpoint(model):\n",
    "    latest_checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "    if not latest_checkpoint_path:\n",
    "        print('Latest checkpoint was not found. Using model as is.')\n",
    "        return model\n",
    "\n",
    "    print('latest_checkpoint_path: ', latest_checkpoint_path)\n",
    "\n",
    "    model.load_weights(latest_checkpoint_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "chemical-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_epoch_from_latest_checkpoint():\n",
    "    latest_checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "    if not latest_checkpoint_path:\n",
    "        print('Latest checkpoint was not found. Starting from epoch #0')\n",
    "        return 0\n",
    "\n",
    "    print('latest_checkpoint_path: ', latest_checkpoint_path)\n",
    "\n",
    "    latest_checkpoint_name = os.path.split(latest_checkpoint_path)[-1]\n",
    "    print('latest_checkpoint_name: ', latest_checkpoint_name)\n",
    "\n",
    "    latest_checkpoint_num = latest_checkpoint_name.split('_')[-1]\n",
    "    print('latest_checkpoint_num: ', latest_checkpoint_num)\n",
    "\n",
    "    return int(latest_checkpoint_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "listed-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_checkpoint(checkpoint_zip_path):\n",
    "    if not os.path.exists(checkpoint_zip_path):\n",
    "        print('Cannot find a specified file')\n",
    "        return\n",
    "\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    with zipfile.ZipFile(checkpoint_zip_path, 'r') as zip_obj:\n",
    "        zip_obj.extractall(checkpoint_dir)\n",
    "\n",
    "    %ls -la ./tmp/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip uploaded checkpoint to checkpoints folder if needed\n",
    "# unzip_checkpoint('ckpt_10.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the latest training data from checkpoints if needed.\n",
    "# model_1 = model_weights_from_latest_checkpoint(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading weights from H5 file if needed.\n",
    "# model_1.load_weights('recipe_generation_rnn_batch_64.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "speaking-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=5,\n",
    "    monitor='loss',\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "norman-defeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_{epoch}')\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "angry-elimination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint was not found. Starting from epoch #0\n",
      "\n",
      "\n",
      "INITIAL_EPOCH:    0\n",
      "EPOCHS_DELTA:     1\n",
      "EPOCHS:           1\n",
      "STEPS_PER_EPOCH:  1500\n"
     ]
    }
   ],
   "source": [
    "INITIAL_EPOCH  = initial_epoch_from_latest_checkpoint()\n",
    "EPOCHS_DELTA = 1\n",
    "EPOCHS = INITIAL_EPOCH + EPOCHS_DELTA\n",
    "STEPS_PER_EPOCH = 1500\n",
    "\n",
    "print('\\n')\n",
    "print('INITIAL_EPOCH:   ', INITIAL_EPOCH)\n",
    "print('EPOCHS_DELTA:    ', EPOCHS_DELTA)\n",
    "print('EPOCHS:          ', EPOCHS)\n",
    "print('STEPS_PER_EPOCH: ', STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "binary-elite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "history_1 = {}\n",
    "# history_1 = {} if not history_1 else history_1\n",
    "print(history_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1[INITIAL_EPOCH] = model_1.fit(\n",
    "    x=dataset_train,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    initial_epoch=INITIAL_EPOCH,\n",
    "    callbacks=[\n",
    "        checkpoint_callback,\n",
    "        early_stopping_callback\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_name = 'recipe_generation_rnn_raw_' + str(INITIAL_EPOCH) + '.h5'\n",
    "model_1.save(model_name, save_format='h5')\n",
    "\n",
    "download_latest_checkpoint(zip_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download zipped latest checkpoint to local drive.\n",
    "# download_latest_checkpoint(zip_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'recipe_generation_rnn_raw_' + INITIAL_EPOCH + '.h5'\n",
    "# model_1.save(model_name, save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_training_history(training_history):\n",
    "    if 'history' in training_history:\n",
    "        loss = training_history.history['loss']\n",
    "    else:\n",
    "        loss = []\n",
    "        for initial_epoch in training_history:\n",
    "            loss += training_history[initial_epoch].history['loss']\n",
    "\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(loss, label='Training set')\n",
    "    plt.legend()\n",
    "    plt.grid(linestyle='--', linewidth=1, alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_training_history(history_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_batch_size = 1\n",
    "\n",
    "model_1_simplified = build_model_1(vocab_size, embedding_dim, rnn_units, simplified_batch_size)\n",
    "\n",
    "model_1_simplified.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model_1_simplified.build(tf.TensorShape([simplified_batch_size, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_simplified.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_simplified.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_generate\n",
    "# - number of characters to generate.\n",
    "#\n",
    "# temperature\n",
    "# - Low temperatures results in more predictable text.\n",
    "# - Higher temperatures results in more surprising text.\n",
    "# - Experiment to find the best setting.\n",
    "def generate_text(model, start_string, num_generate = 1000, temperature=1.0):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "    \n",
    "    padded_start_string = STOP_WORD_TITLE + start_string\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing).\n",
    "    input_indices = np.array(tokenizer.texts_to_sequences([padded_start_string]))\n",
    "\n",
    "    # Empty string to store our results.\n",
    "    text_generated = []\n",
    "\n",
    "    # Here batch size == 1.\n",
    "    model.reset_states()\n",
    "    for char_index in range(num_generate):\n",
    "        predictions = model(input_indices)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # Using a categorical distribution to predict the character returned by the model.\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(\n",
    "            predictions,\n",
    "            num_samples=1\n",
    "        )[-1,0].numpy()\n",
    "\n",
    "        # We pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state.\n",
    "        input_indices = tf.expand_dims([predicted_id], 0)\n",
    "        \n",
    "        next_character = tokenizer.sequences_to_texts(input_indices.numpy())[0]\n",
    "\n",
    "        text_generated.append(next_character)\n",
    "\n",
    "    return (padded_start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combinations(model):\n",
    "    recipe_length = 1000\n",
    "    try_letters = ['', '\\n', 'A', 'B', 'C', 'O', 'L', 'Mushroom', 'Apple', 'Slow', 'Christmass', 'The', 'Banana', 'Homemade']\n",
    "    try_temperature = [1.0, 0.8, 0.4, 0.2]\n",
    "\n",
    "    for letter in try_letters:\n",
    "        for temperature in try_temperature:\n",
    "            generated_text = generate_text(\n",
    "                model,\n",
    "                start_string=letter,\n",
    "                num_generate = recipe_length,\n",
    "                temperature=temperature\n",
    "            )\n",
    "            print(f'Attempt: \"{letter}\" + {temperature}')\n",
    "            print('-----------------------------------')\n",
    "            print(generated_text)\n",
    "            print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_combinations(model_1_simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'recipe_generation_rnn.h5'\n",
    "model_1_simplified.save(model_name, save_format='h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
